# -*- coding: utf-8 -*-
"""MustafaKoca1812901019_FinalOdevi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fiHw8VnUbnkeZo7pkPbXhMnht-Frfg8V
"""

from pyquery import PyQuery as pq
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn import preprocessing
from sklearn.linear_model import LinearRegression
import pickle
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import adjusted_rand_score
from sklearn import datasets
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.metrics import confusion_matrix

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neighbors import KNeighborsClassifier

"""***YAPAY SİNİR AĞI KÜTÜPHANELERİ***"""

from keras.layers import Dense, Dropout, LSTM
from keras import Sequential
import tensorflow as tf
from sklearn.metrics import classification_report, accuracy_score

"""***ÖN İŞLEM KÜTÜPHANELERİ***"""

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
import seaborn as sns

"""# ***BURADA KENDİ VERİ SETİMİZİ OLUŞTURDUK.***"""

arabalistesi=[]

for sayfano in range(1,6):
  p=pq("https://www.sahibinebak.com/vasita/otomobil/fiat-57?page="+str(sayfano))
  for i in p(".searchResultsItem.even.searchResultsPromoHighlight.searchResultsPromoBold.searchResultsFireSale").items():
    liste=[j.text() for j in i("td").items()]
    araba={}    
    araba["seri"]=liste[1]
    if not liste[4]:
      continue
    else:
      araba["model_yili"]=int(liste[4])
    if not liste[5]:
      continue
    else:
      araba["km"]=int(liste[5].replace(".","").replace(" ","").replace("205bin","205000"))
    araba["renk"]=liste[6]
    araba["fiyat"]=int(liste[7][:-3].replace(".",""))
    arabalistesi.append(araba)

verimustafa=pd.DataFrame(arabalistesi) #veri seti haline getirme

verimustafa

len(arabalistesi)

"""***Yıl ve KM değerlerini -1,1 arasında denk gelen değere yazdırıyoruz***"""

#yıl için
scyil=MinMaxScaler()
verimustafa["model_yili"]=scyil.fit_transform(verimustafa["model_yili"].values.reshape(-1,1))
#km için
sckm=MinMaxScaler()
verimustafa["km"]=scyil.fit_transform(verimustafa["km"].values.reshape(-1,1))

verimustafa

verimustafa["renk"].value_counts() #değer sayıları

"""***RENK BEYAZSA 1, DEĞİLSE 0 DÖNDÜR***"""

def renkata(deger):
  if deger!="Beyaz":
    return 0
  else:
    return 1

verimustafa["renk"]=verimustafa["renk"].apply(renkata)

verimustafa

"""***VERİLERİ SİTEDEN BAZEN 65'E KADAR BAZEN 100 ÜZERİ DEĞERE KADAR ÇEKİYOR. HATA ALMAMAK GARANTİ SONUÇ ALMAK İÇİN 60 ÜZERİNDEN İŞLEM YAPTIM!***"""

egitim=verimustafa[:60]
test=verimustafa[60:]

len(test)

"""***EĞİTİM VE TEST İÇİN GEREKLİ OLAN DEĞERLERİ ALIYORUZ***"""

trainX=egitim[["model_yili","km","renk"]].values
trainY=egitim["fiyat"].values

testX=test[["model_yili","km","renk"]].values
testY=test["fiyat"].values

"""***fit komutu ile eğitim yaptık. ***"""

t=LinearRegression()
t.fit(trainX,trainY)

predictY=t.predict(testX)

for i,j in zip(testY,predictY):
  print(i,j)

"""***HEM TAHMİNİ HEM GERÇEK FİYATI YANYANA YAZDIRDIK. 60'DAN EN SON DEĞERE KADAR TEST İÇİN KULLAN DEDİK.***"""

tahmin=pd.DataFrame(predictY,columns=["tahmin"], index=range(60,len(verimustafa)))

pd.concat([test,tahmin],axis=1)

"""***ŞU ANA KADAR OLAN VERİLERİ KAYDET!!!***"""

dosya=open("verimustafa.pckl","wb")
pickle.dump(verimustafa,dosya)

"""***KAYDEDİLEN VERİYİ OKUR, YEDEK VERİ !!!!***"""

dosya2=open("verimustafa.pckl","rb")
verimustafayedek=pickle.load(dosya2)

"""***BURADA VERİ YEDEK'E YENİ DEĞERLER ATANIYOR!!! ÖNEMLİ OLMAZSA HATA ALIYORUM.***"""

normalizec=["fiyat","renk"]
clist={}
for i in normalizec:
  clist[i]=MinMaxScaler()
  verimustafayedek[i]=clist[i].fit_transform(verimustafayedek[i].values.reshape(-1,1))

verimustafayedek.pop("seri") #bu olursa yani silinmezse float hatası veriyor

verimustafayedek

"""# **FARKLI TAHMİN YÖNTEMİ **"""

y=verimustafayedek.pop("fiyat")

trainx2=verimustafayedek[0:60].values
trainy2=y[0:60].values

testx2=verimustafayedek[60:].values
testy2=y[60:].values

tlist={}

slist={}

"""***BURADAKİ DEĞERLERİ DEĞİŞTİREBİLİRİZ. ÇÜNKÜ TEST SONUÇLARINA DİREK ETKİSİ VAR!!!***"""

tlist["tkararagaci"]=DecisionTreeRegressor(min_samples_split=10,min_samples_leaf=5)
tlist["trastgeleorman"]=RandomForestRegressor(min_samples_split=10,min_samples_leaf=5)
tlist["tknn"]=KNeighborsRegressor()

for i in tlist:
  tlist[i].fit(trainx2,trainy2)
  slist[i]=tlist[i].predict(testx2)

clist["fiyat"].inverse_transform

for i in slist:
  slist[i]=clist["fiyat"].inverse_transform(slist[i].reshape(-1,1))

gerceky=clist["fiyat"].inverse_transform(testy2.reshape(-1,1))

c=pd.DataFrame(data=range(60,len(verimustafayedek)),index=range(60,len(verimustafayedek))) #test için kaç veri ayrıldıysa range değeri o

for i in slist:
  c[i]=pd.DataFrame(data=slist[i],index=range(60,len(verimustafayedek)))

c["gercek"]=pd.DataFrame(data=gerceky,index=range(60,len(verimustafayedek)))

c

"""# ***KÜMELEME ALGORİTMASI VE KULLANIMI***

***VERİMUSTAFA'YI KAYDET!!!***
"""

dosyayedek=open("verimustafayedek.pckl","wb")
pickle.dump(verimustafa,dosyayedek)

"""***VERİMUSTAFA'YI OKU***"""

dosyayedek2=open("verimustafayedek.pckl","rb")
verimustafayedek2=pickle.load(dosyayedek2)

verimustafayedek2.pop("seri") #string veriyi siliyoruz

k=KMeans(n_clusters=13) #on uc cesit fiat araba markası var, ayırsın diye
k.fit_transform(verimustafayedek2)

sonuclaryedek=k.transform(verimustafayedek2.values)

k.labels_

verimustafayedek2=pd.concat([verimustafayedek2,pd.DataFrame(k.labels_,columns=["KümeNo"])], axis=1)

verimustafayedek2

#adjusted_rand_score(verimustafayedek2["KümeNo"],k.labels_) #yuzde kac basarısı var ona bakıyor

ak=AgglomerativeClustering(n_clusters=13,linkage="complete",affinity="manhattan")
ak.fit(verimustafayedek2)

ak.labels_

#kume no yazan yere aslında target yazılır. fakat bizde onceden belirli veri olmadıgı için deneme amacli yapıyoruz
#adjusted_rand_score(verimustafayedek2["KümeNo"],k.labels_) #yuzde kac basarısı var ona bakıyor

"""# ***SINIFLANDIRMA İŞLEMLERİ***"""

for i in verimustafayedek2.columns[:-1]:
  verimustafayedek2[i]=MinMaxScaler().fit_transform(verimustafayedek2[i].values.reshape(-1,1))

verimustafayedek2

y=verimustafayedek2["KümeNo"].values
#x=verimustafayedek2[verimustafayedek2.columns[:-1]].values
x=verimustafayedek2.iloc[:,:-1].values

"""***BURADA TRAİN VE TEST YERLERİNİ DÜZGÜN YAZMAK LAZIM YOKSA HATA VERİYOR, SIRALAMASI ÖNEMLİ !!!***"""

trainx3,testx3,trainy3,testy3= train_test_split(x,y,test_size=0.2)

knnDeneme=KNeighborsClassifier(n_neighbors=5)
knnDeneme.fit(trainx3,trainy3)
predy=knnDeneme.predict(testx3)

for i,j in zip(predy,testy3):
  print(i,j)

"""***UZAKLIK HESAPLA***"""

def anahtar(eleman):
  return eleman["uzaklik"]

def uzaklik(a,b):
  toplam = 0
  for i in range(len(a)):
    toplam +=(a[i]-b[i])**2
  return toplam**0.5

uzaklik(testx3[0],trainx3[1])

uzakliklistesi=[]
for i in range(len(trainx3)):
  #print(uzaklik([testx3[0]],[trainx3[i]]),trainy3[i])
  uzakliklistesi.append({"uzaklik":uzaklik(testx3[0],trainx3[i]), "sinif":trainy3[i]})

#uzakliklistesi.sort(key=anahtar)
#uzakliklistesi[:5]

#pd.DataFrame(uzakliklistesi[:3]).groupby("sinif").count().idxmax()[0]
pd.DataFrame(uzakliklistesi[:3]).groupby("sinif").count()

"""# ***KNN KODLAMA***"""

uzakliklistesi

k=5
dogrusayaci=0
tahminlistesi=[]
for testno in range(len(testx3)):
  uzakliklistesi= []
  for egitimno in range(len(trainx3)):
    d=uzaklik([testx3[testno]],[trainx3[egitimno]])
    uzakliklistesi.append({"uzaklik":d,"sinif":trainy3[egitimno]})
  #uzakliklistesi.sort(key=anahtar)
  sonuc=pd.DataFrame(uzakliklistesi[:k]).groupby("sinif").count().idxmax()[0]
  print("tahmin: [{}], Gercek: [{}]".format(sonuc,testy3[testno]))
  if sonuc==testy3[testno]:
    dogrusayaci+=1
  tahminlistesi.append(sonuc)

print("toplam test ornegi ->"+str(len(testx3)))
print("basarili siniflandirma sayaci ->"+str(dogrusayaci))
print("yuzde kac basari -> %"+str(100*(dogrusayaci/len(testx3))))

confusion_matrix(testy3,tahminlistesi)

"""# ***YAPAY SİNİR AĞLARI KODLARI***"""

y=verimustafayedek2["KümeNo"].values
x=verimustafayedek2[verimustafayedek2.columns[:-1]].values

trainx4,testx4,trainy4,testy4=train_test_split(x,y,test_size=0.2)

model=Sequential()
model.add(Dense(13,activation="relu",input_shape=[4]))
model.add(Dense(512,activation="relu"))
model.add(Dense(512,activation="relu"))
model.add(Dense(256,activation="relu"))
model.add(Dense(1,activation="sigmoid"))
model.compile(optimizer="adam",metrics=["accuracy"],loss="binary_crossentropy")

model.summary()

model.fit(trainx4,trainy4,epochs=20)

"""***TENSORFLOW KULLANARAK İNPUT_SHAPE SORUNU KALDIRILDI!***"""

tf.function(experimental_relax_shapes=True)

predy2=model.predict(testx4)

predy_binary=[]
for i in predy2:
  predy_binary.append(int(round(i[0],0)))

predy_binary

accuracy_score(testy4,predy_binary)

classification_report(testy4,predy_binary)

confusion_matrix(testy4,predy_binary)

predy3=model.predict(trainx4)
predy_binary2=[]
for i in predy2:
  predy_binary2.append(int(round(i[0],0)))
accuracy_score(testy4,predy_binary2)

knn2=KNeighborsClassifier(n_neighbors=5)
knn2.fit(trainx4,trainy4)
ypredknn= knn2.predict(testx4)

confusion_matrix(testy4,ypredknn)

"""# **ÖN İŞLEM KODLARI**

***İmputation - Eksik Alanları Tamamlama (GENERAL_DAM_OCCUPANCY_RATE kolonu için)***
"""

verimustafa

seri=verimustafa["seri"]
modelyili=verimustafa["model_yili"]
km=verimustafa["km"]
renk=verimustafa["renk"]
fiyat=verimustafa["fiyat"]

boslaridoldur=SimpleImputer()

seriyatay=seri.values
modelyiliyatay=modelyili.values
kmyatay=km.values

seridikey=seri.values.reshape(-1,1)
modelyilidikey=modelyili.values.reshape(-1,1)
kmdikey=km.values.reshape(-1,1)

boslaridoldur.fit(modelyili.values.reshape(-1,1))

modelyilidolu=boslaridoldur.transform(modelyili.values.reshape(-1,1))

verimustafa.pop("model_yili")

modelyiliDF=pd.DataFrame(data=modelyilidolu, columns=["model_yili"], index=range(0,len(verimustafa)))

verimustafa=pd.concat([verimustafa,modelyiliDF], axis=1)

"""***LabelEncoding***"""

seridelete=verimustafa.pop("seri")

basitkodlayici=LabelEncoder()

seriKodlanmisHali=basitkodlayici.fit_transform(seri.values)

seriKodlanmisHali=seriKodlanmisHali.reshape(-1,1)

seriKodlanmisHaliDF=pd.DataFrame(data=seriKodlanmisHali,columns=["seri"],index=range(0,len(verimustafa)))

verimustafa=pd.concat([verimustafa,seriKodlanmisHaliDF],axis=1)

verimustafa

"""***One Hot Encoder***"""

renkDelete=verimustafa.pop("renk")

SahteKodlayici= OneHotEncoder()

renkKodlanmisHali=SahteKodlayici.fit_transform(renk.values.reshape(-1,1)).toarray()

#renkDF=pd.DataFrame(data=renkKodlanmisHali,columns=["renk"],index=range(0,len(verimustafa)))

"""***Yeni Öznitelik Oluşturma***"""

df=pd.DataFrame(verimustafa)
price=pd.to_datetime(df['model_yili'])
df['yeni_model_yili']=price.dt.year

df

x=df[['model_yili']].values.astype(float)

min_max_scaler=preprocessing.MinMaxScaler()

x_scaled = min_max_scaler.fit_transform(x)

df['model_yili_2_olcek'] = pd.DataFrame(x_scaled)

df

"""***Aykırı veri tespit etme...***"""

sns.boxplot(x=df['model_yili'])